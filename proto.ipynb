{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from groq import Groq\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(temperature=0,\n",
    "                      model_name=\"llama-3.3-70b-specdec\",\n",
    "                      api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "\n",
    "# llm.invoke(\"What is up\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import CohereEmbeddings\n",
    "embeddings = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ssl\n",
    "import certifi\n",
    "from langchain.document_loaders import WebBaseLoader\n",
    "from requests.packages.urllib3.exceptions import InsecureRequestWarning\n",
    "import requests\n",
    "\n",
    "# Disable SSL warnings (use this with caution)\n",
    "requests.packages.urllib3.disable_warnings(InsecureRequestWarning)\n",
    "\n",
    "# Create a custom SSL context that doesn't verify certificates\n",
    "ssl_context = ssl.create_default_context(cafile=certifi.where())\n",
    "ssl_context.check_hostname = False\n",
    "ssl_context.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "# Use the custom SSL context with WebBaseLoader\n",
    "urls = ['https://copyright.gov.in/Copyright_Rules_2013/chapter_i.html',\n",
    "     'https://copyright.gov.in/Copyright_Rules_2013/chapter_ii.html', \n",
    "     'https://copyright.gov.in/Copyright_Rules_2013/chapter_iii.html', \n",
    "     'https://copyright.gov.in/Copyright_Rules_2013/chapter_iv.html', \n",
    "     'https://copyright.gov.in/Copyright_Rules_2013/chapter_v.html', \n",
    "     'https://copyright.gov.in/Copyright_Rules_2013/chapter_vi.html', \n",
    "     'https://copyright.gov.in/Copyright_Rules_2013/chapter_vii.html',\n",
    "      'https://copyright.gov.in/Copyright_Rules_2013/chapter_viii.html',\n",
    "       'https://copyright.gov.in/Copyright_Rules_2013/chapter_ix.html', \n",
    "       'https://copyright.gov.in/Copyright_Rules_2013/chapter_x.html', \n",
    "       'https://copyright.gov.in/Copyright_Rules_2013/chapter_xi.html', \n",
    "       'https://copyright.gov.in/Copyright_Rules_2013/chapter_xii.html', \n",
    "       'https://copyright.gov.in/Copyright_Rules_2013/chapter_xiii.html',\n",
    "        'https://copyright.gov.in/Copyright_Rules_2013/chapter_xiv.html', \n",
    "        'https://copyright.gov.in/Copyright_Rules_2013/chapter_xv.html', \n",
    "        'https://copyright.gov.in/Copyright_Rules_2013/chapter_xvi.html', \n",
    "        'https://copyright.gov.in/Copyright_Rules_2013/chapter_xvii.html',\n",
    "         'https://copyright.gov.in/Copyright_Rules_2013/chapter_xviii.html']\n",
    "\n",
    "docs = []\n",
    "for url in urls:\n",
    "    loader = WebBaseLoader(url)\n",
    "    loader.requests_kwargs = {'verify': False}  # Bypass SSL verification\n",
    "    docs.append(loader.load())\n",
    "\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents after splitting: 352\n",
      "Sample of cleaned text: CHAPTER I THE COPYRIGHT RULES, 2013 CHAPTER I CHAPTER II CHAPTER III CHAPTER IV CHAPTER V CHAPTER VI CHAPTER VII CHAPTER VIII CHAPTER IX CHAPTER X CHAPTER XI CHAPTER XII CHAPTER XIII CHAPTER XIV CHAPT...\n"
     ]
    }
   ],
   "source": [
    "# Split documents into smaller chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=100)\n",
    "split_docs = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Clean up the page content by removing escape characters\n",
    "for i, doc in enumerate(split_docs):\n",
    "    # Replace common escape characters\n",
    "    cleaned_text = doc.page_content.replace('\\n', ' ').replace('\\r', '').replace('\\t', ' ')\n",
    "    # Replace multiple spaces with a single space\n",
    "    cleaned_text = ' '.join(cleaned_text.split())\n",
    "    split_docs[i].page_content = cleaned_text\n",
    "\n",
    "print(f\"Number of documents after splitting: {len(split_docs)}\")\n",
    "if split_docs:\n",
    "    print(f\"Sample of cleaned text: {split_docs[0].page_content[:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_documents(documents=split_docs,\n",
    "                                    embedding=embeddings,\n",
    "                                    collection_name=\"full-context\",\n",
    "                                    persist_directory=\"chroma.db\")\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\":7})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'datasource': 'vectorstore'}\n",
      "The time required to generate response by Router Chain in seconds:1.3437728881835938\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an expert at routing a \n",
    "    user question to a vectorstore or web search. Use the vectorstore for questions on copyright i.e Introduction to the Copyright Act, 1957, The Copyright (Amendment) Act, 2012, Reasons for Amendments, Digital Protection, Internet Service Provider (ISP) Liability, Statutory Licenses, Royalty Rights, Performer Rights, Copyright Societies, Exceptions for the Physically Disabled. You do not need to be stringent with the keywords \n",
    "    in the question related to these topics. Otherwise, use web-search. Give a binary choice 'web_search' \n",
    "    or 'vectorstore' based on the question. Return the a JSON with a single key 'datasource' and \n",
    "    no premable or explaination. Question to route: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "router_llm = ChatGroq(temperature=0,\n",
    "                      model_name=\"llama3-8b-8192\",\n",
    "                      api_key=os.environ.get(\"GROQ_API_KEY\"))\n",
    "start = time.time()\n",
    "question_router = prompt | router_llm | JsonOutputParser()\n",
    "#\n",
    "question = \"What is copyright law?\"\n",
    "print(question_router.invoke({\"question\": question}))\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by Router Chain in seconds:{end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Try to give as much information as possible.\n",
    "    c <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "start = time.time()\n",
    "rag_chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n",
      "The time required to generate response by the retrieval grader in seconds:1.4636421203613281\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no premable or explaination.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n <|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "question = \"Copyright laws and application\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))\n",
    "end = time.time()\n",
    "print(f\"The time required to generate response by the retrieval grader in seconds:{end - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "start = time.time()\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "answer_grader = prompt | llm | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_intent = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    <|begin_of_text|><|start_header_id|>system<|end_header_id|>You are a classifier assessing whether the query given is just asking a\n",
    "    question based on the context or if it is giving a command. Give either 'command' or 'question_answering' to indicate whether\n",
    "    the given query by the user. Provide the intent output in a single key 'intent' and no preamble or explanation.  <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the question/query:\n",
    "    \\n\\n\n",
    "    {question}\n",
    "    \\n\\n\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\"],\n",
    ")\n",
    "\n",
    "intent_classifier = prompt_intent | llm | JsonOutputParser()\n",
    "\n",
    "x = intent_classifier.invoke({\"question\": \"Send a form for appealing copywrite for me\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'intent': 'command'}"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from typing import List, Dict, Any\n",
    "### State\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question : str\n",
    "    generation : str\n",
    "    web_search : str\n",
    "    documents : List[str] = []\n",
    "    context: int # this is the user id\n",
    "    user_data: Dict[str, Any]\n",
    "    form_struct: Dict[str, Any]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def retrieve(state):\n",
    "    \"\"\"\n",
    "    Retrieve documents from vectorstore\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, documents, that contains retrieved documents\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "#\n",
    "def generate(state):\n",
    "    \"\"\"\n",
    "    Generate answer using RAG on retrieved documents\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # RAG generation\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "#\n",
    "def grade_documents(state):\n",
    "    \"\"\"\n",
    "    Determines whether the retrieved documents are relevant to the question\n",
    "    If any document is not relevant, we will set a flag to run web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Filtered out irrelevant documents and updated web_search state\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECK DOCUMENT RELEVANCE TO QUESTION---\")\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = \"No\"\n",
    "    for d in documents:\n",
    "        score = retrieval_grader.invoke({\"question\": question, \"document\": d.page_content})\n",
    "        grade = score['score']\n",
    "        # Document relevant\n",
    "        if grade.lower() == \"yes\":\n",
    "             filtered_docs.append(d)\n",
    "        # Document not relevant\n",
    "        else:\n",
    "            web_search = \"Yes\"\n",
    "            continue\n",
    "    return {\"documents\": filtered_docs, \"question\": question, \"web_search\": web_search}\n",
    "#\n",
    "def web_search(state):\n",
    "    \"\"\"\n",
    "    Web search based based on the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): Appended web results to documents\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    # Initialize documents as empty list if it doesn't exist\n",
    "    documents = state.get(\"documents\", [])\n",
    "\n",
    "    # Web search\n",
    "    docs = web_search_tool.invoke({\"query\": question})\n",
    "    web_results = \"\\n\".join([d[\"content\"] for d in docs])\n",
    "    web_results = Document(page_content=web_results)\n",
    "    if documents:\n",
    "        documents.append(web_results)\n",
    "    else:\n",
    "        documents = [web_results]\n",
    "    return {\"documents\": documents, \"question\": question}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_question(state):\n",
    "    \"\"\"\n",
    "    Route question to web search or RAG.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    print(question)\n",
    "    source = question_router.invoke({\"question\": question})  \n",
    "    print(source)\n",
    "    print(source['datasource'])\n",
    "    if source['datasource'] == 'web_search':\n",
    "         return \"websearch\"\n",
    "    elif source['datasource'] == 'vectorstore':\n",
    "        return \"vectorstore\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_intent(state):\n",
    "    question = state[\"question\"]\n",
    "    classification = intent_classifier.invoke({\"question\": question})\n",
    "    return classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decide_to_generate(state):\n",
    "    \"\"\"\n",
    "    Determines whether to generate an answer, or add web search\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Binary decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    web_search = state[\"web_search\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if web_search == \"Yes\":\n",
    "        # All documents have been filtered check_relevance\n",
    "        # We will re-generate a new query\n",
    "\n",
    "        return \"websearch\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "\n",
    "        return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grade_generation_v_documents_and_question(state):\n",
    "    \"\"\"\n",
    "    Determines whether the generation is grounded in the document and answers question.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Decision for next node to call\n",
    "    \"\"\"\n",
    "\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke({\"documents\": documents, \"generation\": generation})\n",
    "    grade = score['score']\n",
    "\n",
    "    # Check hallucination\n",
    "    if grade == \"yes\":\n",
    "        score = answer_grader.invoke({\"question\": question,\"generation\": generation})\n",
    "        grade = score['score']\n",
    "        if grade == \"yes\":\n",
    "            return \"useful\"\n",
    "        else:\n",
    "            return \"not useful\"\n",
    "    else:\n",
    "        return \"not supported\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_data(state):\n",
    "    \"\"\"\n",
    "    This node doesn't modify the state - it simply passes it through without changes.\n",
    "    This can be useful for debugging or as a placeholder in the workflow.\n",
    "    \n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        state (dict): The unchanged state\n",
    "    \"\"\"\n",
    "    print(\"This goes as an entry for parallel action of getting user data and form data\")\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_data_sql(state):\n",
    "    # Get user data\n",
    "    user_data = {}\n",
    "    return {\"user_data\": user_data}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_form_struct(state):\n",
    "    # form data from RAG\n",
    "\n",
    "    form_struct = {}\n",
    "    return {\"form_struct\": form_struct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_node(state):\n",
    "    # Takes keys from user_data and adds it to form struct\n",
    "    new_form_stuct = {\n",
    "        \"name\": \"sidhant\"\n",
    "    }\n",
    "    return {\"form_struct\": new_form_stuct}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1600a96d0>"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import END, StateGraph\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"websearch\", web_search) # web search\n",
    "workflow.add_node(\"retrieve\", retrieve) # retrieve\n",
    "workflow.add_node(\"grade_documents\", grade_documents) # grade documents\n",
    "workflow.add_node(\"generate\", generate) \n",
    "workflow.add_node(\"entry_data\", entry_data)\n",
    "workflow.add_node(\"user_data_sql\", user_data_sql)\n",
    "workflow.add_node(\"get_form_struct\", get_form_struct)\n",
    "workflow.add_node(\"merge_node\", merge_node)\n",
    "workflow.add_node(\"route_intent\", route_intent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1600a96d0>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.set_conditional_entry_point(\n",
    "    route_question,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"websearch\": \"websearch\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"websearch\", \"generate\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": \"route_intent\",  # Now this points to a valid node\n",
    "        \"not useful\": \"websearch\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"route_intent\",\n",
    "    lambda x: x[\"intent\"],  # Use the output of the route_intent function\n",
    "    {\n",
    "        \"question_answering\": END,\n",
    "        \"command\": \"entry_data\"\n",
    "    }\n",
    ")\n",
    "workflow.add_edge(\"entry_data\", \"user_data_sql\")\n",
    "workflow.add_edge(\"entry_data\", \"get_form_struct\")\n",
    "workflow.add_edge(\"user_data_sql\", \"merge_node\")\n",
    "workflow.add_edge(\"get_form_struct\", \"merge_node\")\n",
    "workflow.add_edge(\"merge_node\", END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = workflow.compile()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON flattened successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def flatten_form_data(json_response):\n",
    "    \"\"\"\n",
    "    Takes a JSON response containing form data and flattens it to a simplified structure.\n",
    "    \n",
    "    Args:\n",
    "        json_response: JSON data containing form structure\n",
    "        \n",
    "    Returns:\n",
    "        dict: Flattened form data structure\n",
    "    \"\"\"\n",
    "    data = json_response if isinstance(json_response, dict) else json.loads(json_response)\n",
    "    \n",
    "    # Create flattened structure\n",
    "    flattened_data = {\n",
    "        \"formId\": data[\"data\"][\"formId\"],\n",
    "        \"formTitle\": data[\"data\"][\"title\"],\n",
    "        \"formDescription\": data[\"data\"][\"description\"]\n",
    "    }\n",
    "    \n",
    "    # Add each field with empty values\n",
    "    for field in data[\"data\"][\"fields\"]:\n",
    "        flattened_data[field[\"label\"]] = \"\"\n",
    "    \n",
    "    return flattened_data\n",
    "\n",
    "\n",
    "\n",
    "with open('data.json', 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "flattened = flatten_form_data(json_data)\n",
    "\n",
    "# Save to a file if needed\n",
    "with open('data_processed.json', 'w') as output_file:\n",
    "    json.dump(flattened, output_file, indent=2)\n",
    "\n",
    "print(\"JSON flattened successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 matching forms\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_cohere import CohereEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import json\n",
    "\n",
    "# Initialize embedding model and vector store\n",
    "embedding_model = CohereEmbeddings(model=\"embed-english-v3.0\")\n",
    "\n",
    "def store_form_data(json_data):\n",
    "    \"\"\"\n",
    "    Store form data in the vector database\n",
    "    \n",
    "    Args:\n",
    "        json_data: JSON data containing form structure\n",
    "        \n",
    "    Returns:\n",
    "        str: Status message\n",
    "    \"\"\"\n",
    "    # Extract title and description for embedding\n",
    "    title = json_data[\"data\"][\"title\"]\n",
    "    description = json_data[\"data\"][\"description\"]\n",
    "    \n",
    "    # Create Document objects\n",
    "    documents = [\n",
    "        Document(page_content=title, metadata={\"source\": \"title\", \"full_data\": json.dumps(json_data)}),\n",
    "        Document(page_content=description, metadata={\"source\": \"description\", \"full_data\": json.dumps(json_data)})\n",
    "    ]\n",
    "    \n",
    "    # Add to vector store\n",
    "    vectorstore = Chroma.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embedding_model,\n",
    "        collection_name=\"form-data\",\n",
    "        persist_directory=\"chroma.db\"\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    \n",
    "    return \"Form data stored successfully in vector database\"\n",
    "\n",
    "def query_form_data(query_text, n_results=1):\n",
    "    \"\"\"\n",
    "    Query the vector database for similar form data\n",
    "    \n",
    "    Args:\n",
    "        query_text: The query text to search for\n",
    "        n_results: Number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        list: Retrieved form data\n",
    "    \"\"\"\n",
    "    # Initialize the vector store\n",
    "    vectorstore = Chroma(\n",
    "        embedding_function=embedding_model,\n",
    "        collection_name=\"form-data\",\n",
    "        persist_directory=\"chroma.db\"\n",
    "    )\n",
    "    \n",
    "    # Search the vector store\n",
    "    results = vectorstore.similarity_search(query_text, k=n_results)\n",
    "    \n",
    "    # Extract and return the JSON data\n",
    "    retrieved_data = []\n",
    "    for doc in results:\n",
    "        try:\n",
    "            # Parse the JSON from metadata\n",
    "            full_data = json.loads(doc.metadata[\"full_data\"])\n",
    "            retrieved_data.append({\n",
    "                \"data\": full_data\n",
    "            })\n",
    "        except Exception as e:\n",
    "            retrieved_data.append({\"error\": str(e), \"content\": doc.page_content})\n",
    "    \n",
    "    return retrieved_data\n",
    "\n",
    "def process_and_store_json_file(file_path):\n",
    "    \"\"\"\n",
    "    Load JSON data from a file, process it, and store it in the vector database\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file\n",
    "        \n",
    "    Returns:\n",
    "        str: Status message\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            json_data = json.load(file)\n",
    "        \n",
    "        result = store_form_data(json_data)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        return f\"Error processing file: {str(e)}\"\n",
    "\n",
    "\n",
    "# Example query to retrieve the form data\n",
    "query_result = query_form_data(\"copyright registration form\")\n",
    "print(f\"Found {len(query_result)} matching forms\")\n",
    "x = query_result[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"data\": {\"message\": \"Form data retrieved successfully for ML processing.\", \"data\": {\"formId\": 1, \"title\": \"FORM XIV - APPLICATION FOR REGISTRATION OF COPYRIGHT [SEE RULE 70]\", \"description\": \"\\\\n    FORM XIV - APPLICATION FOR REGISTRATION OF COPYRIGHT\\\\n    For applying to the Registrar of Copyrights, Copyright Office, New Delhi\\\\n    for registration of copyright in accordance with section 45 of the Copyright Act, 1957 (14 of 1957).\\\\n  \", \"metadata\": {\"createdAt\": \"2025-03-23T04:01:54.727Z\", \"updatedAt\": \"2025-03-23T04:01:54.727Z\"}, \"fields\": [{\"id\": 1, \"label\": \"Applicant Name\", \"description\": \"Full name of the applicant\", \"type\": \"TEXT\", \"required\": true, \"validations\": {\"maxLength\": 200, \"minLength\": 3}, \"order\": 1}, {\"id\": 2, \"label\": \"Applicant Address\", \"description\": \"Complete address of the applicant\", \"type\": \"TEXTAREA\", \"required\": true, \"validations\": {\"maxLength\": 500, \"minLength\": 10}, \"order\": 2}, {\"id\": 3, \"label\": \"Applicant Nationality\", \"description\": \"Nationality of the applicant\", \"type\": \"TEXT\", \"required\": true, \"validations\": {\"maxLength\": 100, \"minLength\": 2}, \"order\": 3}, {\"id\": 4, \"label\": \"Applicant Category\", \"description\": \"Category of the applicant\", \"type\": \"SELECT\", \"required\": true, \"validations\": {\"options\": [\"Individual\", \"Business\", \"Others\"]}, \"order\": 4}, {\"id\": 5, \"label\": \"Work Title\", \"description\": \"Title of the work for copyright registration\", \"type\": \"TEXT\", \"required\": true, \"validations\": {\"maxLength\": 200, \"minLength\": 1}, \"order\": 5}, {\"id\": 6, \"label\": \"Work Description\", \"description\": \"Description of the work\", \"type\": \"TEXTAREA\", \"required\": true, \"validations\": {\"maxLength\": 500, \"minLength\": 10}, \"order\": 6}, {\"id\": 7, \"label\": \"Work Class\", \"description\": \"Class of the work\", \"type\": \"SELECT\", \"required\": true, \"validations\": {\"options\": [\"Literary\", \"Dramatic\", \"Musical\", \"Artistic\", \"Cinematograph Film\", \"Sound Recording\", \"Computer Software\"]}, \"order\": 7}, {\"id\": 8, \"label\": \"Work Language\", \"description\": \"Language of the work\", \"type\": \"TEXT\", \"required\": true, \"validations\": {\"maxLength\": 50, \"minLength\": 2}, \"order\": 8}, {\"id\": 9, \"label\": \"Author Name\", \"description\": \"Full name of the author\", \"type\": \"TEXT\", \"required\": true, \"validations\": {\"maxLength\": 200, \"minLength\": 3}, \"order\": 9}, {\"id\": 10, \"label\": \"Author Address\", \"description\": \"Address of the author\", \"type\": \"TEXTAREA\", \"required\": true, \"validations\": {\"maxLength\": 500, \"minLength\": 10}, \"order\": 10}, {\"id\": 11, \"label\": \"Publication Status\", \"description\": \"Is the work published or unpublished?\", \"type\": \"SELECT\", \"required\": true, \"validations\": {\"options\": [\"Published\", \"Unpublished\"]}, \"order\": 11}, {\"id\": 12, \"label\": \"Publisher Details\", \"description\": \"Name and address of the publisher\", \"type\": \"TEXTAREA\", \"required\": false, \"validations\": {\"maxLength\": 300, \"minLength\": 0}, \"order\": 12}, {\"id\": 13, \"label\": \"Year of First Publication\", \"description\": \"Year when the work was first published\", \"type\": \"NUMBER\", \"required\": false, \"validations\": {\"max\": 2025, \"min\": 1800}, \"order\": 13}, {\"id\": 14, \"label\": \"Fee Payment Details\", \"description\": \"Details of payment of registration fee\", \"type\": \"TEXT\", \"required\": true, \"validations\": {\"maxLength\": 100, \"minLength\": 5}, \"order\": 14}, {\"id\": 15, \"label\": \"Declaration\", \"description\": \"I verify that particulars given in this form are true to the best of my knowledge\", \"type\": \"CHECKBOX\", \"required\": true, \"validations\": {}, \"order\": 15}, {\"id\": 16, \"label\": \"Work Sample\", \"description\": \"Upload a copy of the work for which registration is sought\", \"type\": \"FILE\", \"required\": true, \"validations\": {\"maxSize\": 10, \"fileTypes\": [\"pdf\", \"docx\", \"jpg\", \"png\"]}, \"order\": 16}]}}}'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "json.dumps(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieved 0 forms matching the query\n"
     ]
    }
   ],
   "source": [
    "query_result = query_form_data(\"copyright\")\n",
    "print(f\"Retrieved {len(query_result)} forms matching the query\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
